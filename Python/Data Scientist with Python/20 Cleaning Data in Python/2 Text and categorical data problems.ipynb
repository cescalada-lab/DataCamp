{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "airlines = pd.read_csv(\"airlines_final.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame categories :\n",
    "cleanliness= airlines['cleanliness'].unique()\n",
    "safety=airlines['safety'].unique()\n",
    "satisfaction=airlines['satisfaction'].unique()\n",
    "\n",
    "dictionary = {'cleanliness':cleanliness, 'safety':safety, 'satisfaction':satisfaction}\n",
    "categories = pd.DataFrame(dictionary)\n",
    "\n",
    "categories.to_csv('categories.csv')\n",
    "#https://www.geeksforgeeks.org/saving-a-pandas-dataframe-as-a-csv/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Members only\n",
    "\n",
    "Throughout the course so far, you've been exposed to some common problems that you may encounter with your data, from data type constraints, data range constrains, uniqueness constraints, and now membership constraints for categorical values.\n",
    "\n",
    "In this exercise, you will map hypothetical problems to their respective categories.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Map the data problem observed with the correct type of data problem.\n",
    "\n",
    "## ANSWERS:\n",
    "\n",
    "* Membership Constraint:\n",
    "    * GPA column containing -Z grade.\n",
    "    * day_of_week column with the value suntermonday.\n",
    "    * has_loan column with value 12.\n",
    "    * month column with value 14.\n",
    "\n",
    "##\n",
    "* Other Constraint:\n",
    "    * revenue column represented as string.\n",
    "    * birthdate column with values in the future. \n",
    "    * age column with values above 130.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding consistency\n",
    "\n",
    "In this exercise and throughout this chapter, you'll be working with the airlines DataFrame which contains survey responses on the San Francisco Airport from airline customers.\n",
    "\n",
    "The DataFrame contains flight metadata such as the airline, the destination, waiting times as well as answers to key questions regarding cleanliness, safety, and satisfaction. Another DataFrame named categories was created, containing all correct possible values for the survey columns.\n",
    "\n",
    "In this exercise, you will use both of these DataFrames to find survey answers with inconsistent values, and drop them, effectively performing an outer and inner join on both these DataFrames as seen in the video exercise. The pandas package has been imported as pd, and the airlines and categories DataFrames are in your environment.\n",
    "\n",
    "## Instructions 1/4\n",
    "\n",
    "* Print the categories DataFrame and take a close look at all possible correct categories of the survey columns.\n",
    "* Print the unique values of the survey columns in airlines using the .unique() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cleanliness           safety          satisfaction\n",
      "0           Clean          Neutral        Very satisfied\n",
      "1         Average        Very safe               Neutral\n",
      "2  Somewhat clean    Somewhat safe    Somewhat satsified\n",
      "3  Somewhat dirty      Very unsafe  Somewhat unsatisfied\n",
      "4           Dirty  Somewhat unsafe      Very unsatisfied\n",
      "Cleanliness:  ['Clean' 'Average' 'Somewhat clean' 'Somewhat dirty' 'Dirty'] \n",
      "\n",
      "Safety:  ['Neutral' 'Very safe' 'Somewhat safe' 'Very unsafe' 'Somewhat unsafe'] \n",
      "\n",
      "Satisfaction:  ['Very satisfied' 'Neutral' 'Somewhat satsified' 'Somewhat unsatisfied'\n",
      " 'Very unsatisfied'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print categories DataFrame\n",
    "print(categories)\n",
    "\n",
    "# Print unique values of survey columns in airlines\n",
    "print('Cleanliness: ', airlines['cleanliness'].unique(), \"\\n\")\n",
    "print('Safety: ', airlines['safety'].unique(), \"\\n\")\n",
    "print('Satisfaction: ', airlines['satisfaction'].unique(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions 2/4\n",
    "\n",
    "## Question\n",
    "\n",
    "Take a look at the output. Out of the cleanliness, safety and satisfaction columns, which one has an inconsistent category and what is it?\n",
    "\n",
    "## ANSWER: \n",
    "\n",
    "* cleanliness because it has an `Unacceptable` category.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions 3/4\n",
    "\n",
    "* Create a set out of the cleanliness column in airlines using set() and find the inconsistent category by finding the difference in the cleanliness column of categories.\n",
    "* Find rows of airlines with a cleanliness value not in categories and print the output.\n",
    "\n",
    "## Instructions 4/4\n",
    "* Print the rows with the consistent categories of cleanliness only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, day, airline, destination, dest_region, dest_size, boarding_area, dept_time, wait_min, cleanliness, safety, satisfaction]\n",
      "Index: []\n",
      "        id        day        airline        destination    dest_region  \\\n",
      "0     1351    Tuesday    UNITED INTL             KANSAI           Asia   \n",
      "1      373     Friday         ALASKA  SAN JOSE DEL CABO  Canada/Mexico   \n",
      "2     2820   Thursday          DELTA        LOS ANGELES        West US   \n",
      "3     1157    Tuesday      SOUTHWEST        LOS ANGELES        West US   \n",
      "4     2992  Wednesday       AMERICAN              MIAMI        East US   \n",
      "...    ...        ...            ...                ...            ...   \n",
      "2804  1475    Tuesday         ALASKA       NEW YORK-JFK        East US   \n",
      "2805  2222   Thursday      SOUTHWEST            PHOENIX        West US   \n",
      "2806  2684     Friday         UNITED            ORLANDO        East US   \n",
      "2807  2549    Tuesday        JETBLUE         LONG BEACH        West US   \n",
      "2808  2162   Saturday  CHINA EASTERN            QINGDAO           Asia   \n",
      "\n",
      "     dest_size boarding_area   dept_time  wait_min     cleanliness  \\\n",
      "0          Hub  Gates 91-102  2018-12-31     115.0           Clean   \n",
      "1        Small   Gates 50-59  2018-12-31     135.0           Clean   \n",
      "2          Hub   Gates 40-48  2018-12-31      70.0         Average   \n",
      "3          Hub   Gates 20-39  2018-12-31     190.0           Clean   \n",
      "4          Hub   Gates 50-59  2018-12-31     559.0  Somewhat clean   \n",
      "...        ...           ...         ...       ...             ...   \n",
      "2804       Hub   Gates 50-59  2018-12-31     280.0  Somewhat clean   \n",
      "2805       Hub   Gates 20-39  2018-12-31     165.0           Clean   \n",
      "2806       Hub   Gates 70-90  2018-12-31      92.0           Clean   \n",
      "2807     Small    Gates 1-12  2018-12-31      95.0           Clean   \n",
      "2808     Large    Gates 1-12  2018-12-31     220.0           Clean   \n",
      "\n",
      "             safety        satisfaction  \n",
      "0           Neutral      Very satisfied  \n",
      "1         Very safe      Very satisfied  \n",
      "2     Somewhat safe             Neutral  \n",
      "3         Very safe  Somewhat satsified  \n",
      "4         Very safe  Somewhat satsified  \n",
      "...             ...                 ...  \n",
      "2804        Neutral  Somewhat satsified  \n",
      "2805      Very safe      Very satisfied  \n",
      "2806      Very safe      Very satisfied  \n",
      "2807  Somewhat safe      Very satisfied  \n",
      "2808      Very safe  Somewhat satsified  \n",
      "\n",
      "[2477 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find the cleanliness category in airlines not in categories\n",
    "cat_clean = set(airlines['cleanliness']).difference(categories['cleanliness'])\n",
    "\n",
    "# Find rows with that category\n",
    "cat_clean_rows = airlines['cleanliness'].isin(cat_clean)\n",
    "\n",
    "# Print rows with inconsistent category\n",
    "print(airlines[cat_clean_rows])\n",
    "\n",
    "# Print rows with consistent categories only\n",
    "print(airlines[~cat_clean_rows])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categories of errors\n",
    "\n",
    "In the video exercise, you saw how to address common problems affecting categorical variables in your data, including white spaces and inconsistencies in your categories, and the problem of creating new categories and mapping existing ones to new ones.\n",
    "\n",
    "To get a better idea of the toolkit at your disposal, you will be mapping functions and methods from pandas and Python used to address each type of problem.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Map each function/method to the categorical data problem it solves.\n",
    "\n",
    "* White spaces and inconsistency\n",
    "    * `str.trip()`\n",
    "    * `str.upper()`\n",
    "    * `str.lower()`\n",
    "\n",
    "\n",
    "* Creating or remapping categories\n",
    "    * `pandas.cut()`\n",
    "    * `replace()`\n",
    "    * `pandas.qcut()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inconsistent categories\n",
    "\n",
    "In this exercise, you'll be revisiting the airlines DataFrame from the previous lesson.\n",
    "\n",
    "As a reminder, the DataFrame contains flight metadata such as the airline, the destination, waiting times as well as answers to key questions regarding cleanliness, safety, and satisfaction on the San Francisco Airport.\n",
    "\n",
    "In this exercise, you will examine two categorical columns from this DataFrame, dest_region and dest_size respectively, assess how to address them and make sure that they are cleaned and ready for analysis. The pandas package has been imported as pd, and the airlines DataFrame is in your environment.\n",
    "\n",
    "## Instructions 1/4\n",
    "\n",
    "* Print the unique values in dest_region and dest_size respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asia' 'Canada/Mexico' 'West US' 'East US' 'Midwest US' 'EAST US'\n",
      " 'Middle East' 'Europe' 'eur' 'Central/South America'\n",
      " 'Australia/New Zealand' 'middle east']\n",
      "['Hub' 'Small' '    Hub' 'Medium' 'Large' 'Hub     ' '    Small'\n",
      " 'Medium     ' '    Medium' 'Small     ' '    Large' 'Large     ']\n"
     ]
    }
   ],
   "source": [
    "# Print unique values of both columns\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions 2/4\n",
    "\n",
    "## Question\n",
    "\n",
    "From looking at the output, what do you think is the problem with these columns?\n",
    "\n",
    "## Possible Answers\n",
    "\n",
    "* The dest_region column has only inconsistent values due to capitalization.\n",
    "\n",
    "* The dest_region column has inconsistent values due to capitalization and has one value that needs to be remapped.\n",
    "\n",
    "* The dest_size column has only inconsistent values due to leading and trailing spaces.\n",
    "\n",
    "* Both 2 and 3 are correct.\n",
    "\n",
    "## ANSWER:\n",
    "\n",
    "* Both 2 and 3 are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions 3/4\n",
    "\n",
    "* Change the capitalization of all values of dest_region to lowercase.\n",
    "* Replace the 'eur' with 'europe' in dest_region using the .replace() method.\n",
    "\n",
    "## Instructions 4/4\n",
    "\n",
    "* Strip white spaces from the dest_size column using the .strip() method.\n",
    "* Verify that the changes have been into effect by printing the unique values of the columns using .unique() ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asia' 'canada/mexico' 'west us' 'east us' 'midwest us' 'middle east'\n",
      " 'europe' 'central/south america' 'australia/new zealand']\n",
      "['Hub' 'Small' '    Hub' 'Medium' 'Large' 'Hub     ' '    Small'\n",
      " 'Medium     ' '    Medium' 'Small     ' '    Large' 'Large     ']\n",
      "0                asia\n",
      "1       canada/mexico\n",
      "2             west us\n",
      "3             west us\n",
      "4             east us\n",
      "            ...      \n",
      "2804          east us\n",
      "2805          west us\n",
      "2806          east us\n",
      "2807          west us\n",
      "2808             asia\n",
      "Name: dest_region, Length: 2477, dtype: object\n",
      "0         Hub\n",
      "1       Small\n",
      "2         Hub\n",
      "3         Hub\n",
      "4         Hub\n",
      "        ...  \n",
      "2804      Hub\n",
      "2805      Hub\n",
      "2806      Hub\n",
      "2807    Small\n",
      "2808    Large\n",
      "Name: dest_size, Length: 2477, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print unique values of both columns\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())\n",
    "\n",
    "# Lower dest_region column and then replace \"eur\" with \"europe\"\n",
    "airlines['dest_region'] = airlines['dest_region'].str.lower() \n",
    "airlines['dest_region'] = airlines['dest_region'].replace({'eur':'europe'})\n",
    "\n",
    "# Remove white spaces from `dest_size`\n",
    "airlines['dest_size'] = airlines['dest_size'].str.strip()\n",
    "\n",
    "# Verify changes have been effected\n",
    "print(airlines['dest_region'])\n",
    "print(airlines['dest_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remapping categories\n",
    "\n",
    "To better understand survey respondents from airlines, you want to find out if there is a relationship between certain responses and the day of the week and wait time at the gate.\n",
    "\n",
    "The airlines DataFrame contains the day and wait_min columns, which are categorical and numerical respectively. The day column contains the exact day a flight took place, and wait_min contains the amount of minutes it took travelers to wait at the gate. To make your analysis easier, you want to create two new categorical variables:\n",
    "\n",
    "wait_type: 'short' for 0-60 min, 'medium' for 60-180 and long for 180+\n",
    "day_week: 'weekday' if day is in the weekday, 'weekend' if day is in the weekend.\n",
    "The pandas and numpy packages have been imported as pd and np. Let's create some new categorical data!\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Create the ranges and labels for the wait_type column mentioned in the description.\n",
    "* Create the wait_type column by from wait_min by using pd.cut(), while inputting label_ranges and label_names in the correct arguments.\n",
    "* Create the mapping dictionary mapping weekdays to 'weekday' and weekend days to 'weekend'.\n",
    "* Create the day_week column by using .replace()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create ranges for categories\n",
    "label_ranges = [0, 60, 180, np.inf]\n",
    "label_names = ['short', 'medium', 'long']\n",
    "\n",
    "# Create wait_type column\n",
    "airlines['wait_type'] = pd.cut(airlines['wait_min'], bins = label_ranges, \n",
    "                                labels = label_names)\n",
    "\n",
    "# Create mappings and replace\n",
    "mappings = {'Monday':'weekday', 'Tuesday':'weekday', 'Wednesday': 'weekday', 'Thursday': 'weekday', 'Friday': 'weekday', \n",
    "            'Saturday': 'weekend', 'Sunday': 'weekend'}\n",
    "\n",
    "airlines['day_week'] = airlines['day'].replace(mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing titles and taking names\n",
    "\n",
    "While collecting survey respondent metadata in the airlines DataFrame, the full name of respondents was saved in the full_name column. However upon closer inspection, you found that a lot of the different names are prefixed by honorifics such as \"Dr.\", \"Mr.\", \"Ms.\" and \"Miss\".\n",
    "\n",
    "Your ultimate objective is to create two new columns named first_name and last_name, containing the first and last names of respondents respectively. Before doing so however, you need to remove honorifics.\n",
    "\n",
    "The airlines DataFrame is in your environment, alongside pandas as pd.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Remove \"Dr.\", \"Mr.\", \"Miss\" and \"Ms.\" from full_name by replacing them with an empty string \"\" in that order.\n",
    "* Run the assert statement using .str.contains() that tests whether full_name still contains any of the honorifics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos la columna full_names\n",
    "full_name=['Melodie Stuart', 'Dominic Shannon', 'Quintessa Tillman', 'Dr. Christine Nicholson', 'Regina Clements', 'Colleen Harding', 'Kaitlin Cochran', 'Molly Norton', 'Richard Lott', 'Matthew Nguyen', 'Dr. Laith Decker', 'Holly Austin', 'Jaden Gray', 'Germaine Hurley', 'Kyle Gay', 'Zachery Diaz', 'Carolyn Hartman', 'Miss Alana Grant', 'Idola Acosta', 'Dara English', 'Miss Aurora Flores', 'Henry Sloan', 'Jared Chase', 'Xavier Castro', 'Holmes Fowler', 'Lucy Noel', 'Kerry Tucker', 'Garrison Barrett', 'Stephanie Cannon', 'Dr. Charlotte Savage', 'Lane Clements', 'Aimee Whitfield', 'Martena Neal', 'Xandra Hartman', 'Meredith Gutierrez', 'Mr. Kermit Deleon', 'Derek Terrell', 'Shaeleigh Mccarthy', 'Burke Leon', 'Mr. Clinton Holmes', 'Whoopi Tillman', 'Hamilton Gardner', 'Graiden Bridges', 'Sheila Robinson', 'Cameron Barlow', 'Kasimir Irwin', 'Ms. Lilah Chen', 'Judith Price', 'Dane Barker', 'Micah Bullock', 'Leonard Stevens', 'Ms. Beverly Hampton', 'Devin Morrison', 'Mr. Jordan Cooke', 'Miss Ann Hale', 'Graiden Riddle', 'Julian Stanley', 'Christine Carter', 'Hasad Valentine', 'Bevis Mcdowell', 'Alec Davis', 'Dr. Daniel Hood', 'Ms. Britanney Schmidt', 'Wanda Jackson', 'Quyn Henderson', 'Hammett Duncan', 'Duncan Stark', 'Jin Shannon', 'Fulton Meadows', 'Dr. Malik Hanson', 'Laith Espinoza', 'Dr. Jared Holman', 'Julie Davidson', 'Dr. Jane Harrell', 'Aphrodite Shannon', 'Jermaine Randall', 'Hammett Talley', 'Sasha Riggs', 'Dr. Damian Wynn', 'Aidan Macias', 'Sawyer Hines', 'Mr. Hector Caldwell', 'Abra Webb', 'Stone Price', 'Cheyenne Stout', 'Lareina Wall', 'Dr. Ella Pena', 'Quintessa Sherman', 'Ishmael Duffy', 'Ms. Willa Stuart', 'Gareth Hunt', 'Stewart Jacobs', 'Ms. Amaya Pate', 'Dr. Xavier Medina', 'Mr. Marvin Mcneil', 'Imogene Harris', 'Abbot Hensley', 'Miss Fiona Velez', 'Rinah Stephenson', 'Ms. Olivia Keith', 'Vielka Rosario', 'Lani Sawyer', 'Clayton Sparks', 'Oprah Ingram', 'Acton Smith', 'Demetria Byrd', 'Patience Galloway', 'Hoyt Alvarez', 'Dara Pennington', 'Ebony Davidson', 'Brent Rosario', 'Melyssa Mayer', 'Regan Kelly', 'Leah Barlow', 'Nathan Santos', 'Uta Mckee', 'Lawrence Gallegos', 'Matthew Edwards', 'Xander Wilson', 'Kelly Pittman', 'Brynne Pugh', 'Shea Collins', 'Hu Carver', 'Stacey Coleman', 'Kaye Mcgowan', 'Vivien Cobb', 'Vaughan Harrison', 'Porter Hudson', 'Carl Conway', 'Lyle Bradshaw', 'Hashim Walter', 'Branden Larson', 'Idola Ball', 'Camilla White', 'Rafael Lowery', 'Victor Leon', 'Yasir Lynch', 'Dr. Emerson Woodard', 'Dr. Astra Mcneil', 'Dr. Shafira Marks', 'Mr. Dominic Smith', 'Talon Holder', 'Ivor Wise', 'Carolyn Clay', 'Jerome Ruiz', 'Todd Chase', 'Gray Noel', 'Ann Sanchez', 'Mr. Alec Heath', 'Heidi Terry', 'Alana Velasquez', 'Mr. Jared York', 'Abbot Lester', 'Dr. Fulton Turner', 'Dr. Maggie Cortez', 'Ramona Wade', 'Dr. Lynn Thomas', 'Aquila Graham', 'Gareth Marks', 'Dolan Wolf', 'Julie Coffey', 'Emerson Hatfield', 'Claire Rios', 'Christian Doyle', 'Haley Oliver', 'Rigel Day', 'Clare Gould', 'Ms. Keiko Mcfarland', 'Duncan Chandler', 'Penelope Stark', 'Kasper Shields', 'Dr. Rose Fleming', 'Miss Petra Mitchell', 'Ms. Regan Lynch', 'Keane Bennett', 'Nash Head', 'Ainsley Riley', 'Kirestin Newton', 'Jakeem Hall', 'Reece Mitchell', 'Wanda Walls', 'Barry Mccray', 'Dr. Zahir Hardin', 'Graiden Cox', 'Miss Lara Green', 'Felix Bell', 'Mr. Addison Day', 'Tallulah Guzman', 'Jocelyn Guzman', 'Ivory Miller', 'Mr. Eaton Vazquez', 'Silas Clemons', 'Quinn Barry', 'Orson Pratt', 'Constance Morse', 'Ms. Vanna Rivera', 'Miss Venus Lowe', 'Amethyst Nieves', 'Miss Vivian Foreman', 'Miss Wendy Griffin']\n",
    "airlines['full_name'] = pd.DataFrame(full_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Melodie Stuart', 'Dominic Shannon', 'Quintessa Tillman', 'Dr. Christine Nicholson', 'Regina Clements', 'Colleen Harding', 'Kaitlin Cochran', 'Molly Norton', 'Richard Lott', 'Matthew Nguyen', 'Dr. Laith Decker', 'Holly Austin', 'Jaden Gray', 'Germaine Hurley', 'Kyle Gay', 'Zachery Diaz', 'Carolyn Hartman', 'Miss Alana Grant', 'Idola Acosta', 'Dara English', 'Miss Aurora Flores', 'Henry Sloan', 'Jared Chase', 'Xavier Castro', 'Holmes Fowler', 'Lucy Noel', 'Kerry Tucker', 'Garrison Barrett', 'Stephanie Cannon', 'Dr. Charlotte Savage', 'Lane Clements', 'Aimee Whitfield', 'Martena Neal', 'Xandra Hartman', 'Meredith Gutierrez', 'Mr. Kermit Deleon', 'Derek Terrell', 'Shaeleigh Mccarthy', 'Burke Leon', 'Mr. Clinton Holmes', 'Whoopi Tillman', 'Hamilton Gardner', 'Graiden Bridges', 'Sheila Robinson', 'Cameron Barlow', 'Kasimir Irwin', 'Ms. Lilah Chen', 'Judith Price', 'Dane Barker', 'Micah Bullock', 'Leonard Stevens', 'Ms. Beverly Hampton', 'Devin Morrison', 'Mr. Jordan Cooke', 'Miss Ann Hale', 'Graiden Riddle', 'Julian Stanley', 'Christine Carter', 'Hasad Valentine', 'Bevis Mcdowell', 'Alec Davis', 'Dr. Daniel Hood', 'Ms. Britanney Schmidt', 'Wanda Jackson', 'Quyn Henderson', 'Hammett Duncan', 'Duncan Stark', 'Jin Shannon', 'Fulton Meadows', 'Dr. Malik Hanson', 'Laith Espinoza', 'Dr. Jared Holman', 'Julie Davidson', 'Dr. Jane Harrell', 'Aphrodite Shannon', 'Jermaine Randall', 'Hammett Talley', 'Sasha Riggs', 'Dr. Damian Wynn', 'Aidan Macias', 'Sawyer Hines', 'Mr. Hector Caldwell', 'Abra Webb', 'Stone Price', 'Cheyenne Stout', 'Lareina Wall', 'Dr. Ella Pena', 'Quintessa Sherman', 'Ishmael Duffy', 'Ms. Willa Stuart', 'Gareth Hunt', 'Stewart Jacobs', 'Ms. Amaya Pate', 'Dr. Xavier Medina', 'Mr. Marvin Mcneil', 'Imogene Harris', 'Abbot Hensley', 'Miss Fiona Velez', 'Rinah Stephenson', 'Ms. Olivia Keith', 'Vielka Rosario', 'Lani Sawyer', 'Clayton Sparks', 'Oprah Ingram', 'Acton Smith', 'Demetria Byrd', 'Patience Galloway', 'Hoyt Alvarez', 'Dara Pennington', 'Ebony Davidson', 'Brent Rosario', 'Melyssa Mayer', 'Regan Kelly', 'Leah Barlow', 'Nathan Santos', 'Uta Mckee', 'Lawrence Gallegos', 'Matthew Edwards', 'Xander Wilson', 'Kelly Pittman', 'Brynne Pugh', 'Shea Collins', 'Hu Carver', 'Stacey Coleman', 'Kaye Mcgowan', 'Vivien Cobb', 'Vaughan Harrison', 'Porter Hudson', 'Carl Conway', 'Lyle Bradshaw', 'Hashim Walter', 'Branden Larson', 'Idola Ball', 'Camilla White', 'Rafael Lowery', 'Victor Leon', 'Yasir Lynch', 'Dr. Emerson Woodard', 'Dr. Astra Mcneil', 'Dr. Shafira Marks', 'Mr. Dominic Smith', 'Talon Holder', 'Ivor Wise', 'Carolyn Clay', 'Jerome Ruiz', 'Todd Chase', 'Gray Noel', 'Ann Sanchez', 'Mr. Alec Heath', 'Heidi Terry', 'Alana Velasquez', 'Mr. Jared York', 'Abbot Lester', 'Dr. Fulton Turner', 'Dr. Maggie Cortez', 'Ramona Wade', 'Dr. Lynn Thomas', 'Aquila Graham', 'Gareth Marks', 'Dolan Wolf', 'Julie Coffey', 'Emerson Hatfield', 'Claire Rios', 'Christian Doyle', 'Haley Oliver', 'Rigel Day', 'Clare Gould', 'Ms. Keiko Mcfarland', 'Duncan Chandler', 'Penelope Stark', 'Kasper Shields', 'Dr. Rose Fleming', 'Miss Petra Mitchell', 'Ms. Regan Lynch', 'Keane Bennett', 'Nash Head', 'Ainsley Riley', 'Kirestin Newton', 'Jakeem Hall', 'Reece Mitchell', 'Wanda Walls', 'Barry Mccray', 'Dr. Zahir Hardin', 'Graiden Cox', 'Miss Lara Green', 'Felix Bell', 'Mr. Addison Day', 'Tallulah Guzman', 'Jocelyn Guzman', 'Ivory Miller', 'Mr. Eaton Vazquez', 'Silas Clemons', 'Quinn Barry', 'Orson Pratt', 'Constance Morse', 'Ms. Vanna Rivera', 'Miss Venus Lowe', 'Amethyst Nieves', 'Miss Vivian Foreman', 'Miss Wendy Griffin']\n"
     ]
    }
   ],
   "source": [
    "print(full_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2211/3304348909.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  airlines['full_name'] = airlines['full_name'].str.replace(\"Dr.\",\"\")\n",
      "/tmp/ipykernel_2211/3304348909.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  airlines['full_name'] = airlines['full_name'].str.replace(\"Mr.\",\"\")\n",
      "/tmp/ipykernel_2211/3304348909.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  airlines['full_name'] = airlines['full_name'].str.replace(\"Ms.\",\"\")\n"
     ]
    }
   ],
   "source": [
    "# Replace \"Dr.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Dr.\",\"\")\n",
    "\n",
    "# Replace \"Mr.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Mr.\",\"\")\n",
    "\n",
    "# Replace \"Miss\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Miss\",\"\")\n",
    "\n",
    "# Replace \"Ms.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Ms.\",\"\")\n",
    "\n",
    "# Assert that full_name has no honorifics\n",
    "assert airlines['full_name'].str.contains('Ms.|Mr.|Miss|Dr.').any() == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keeping it descriptive\n",
    "\n",
    "To further understand travelers' experiences in the San Francisco Airport, the quality assurance department sent out a qualitative questionnaire to all travelers who gave the airport the worst score on all possible categories. The objective behind this questionnaire is to identify common patterns in what travelers are saying about the airport.\n",
    "\n",
    "Their response is stored in the survey_response column. Upon a closer look, you realized a few of the answers gave the shortest possible character amount without much substance. In this exercise, you will isolate the responses with a character count higher than 40 , and make sure your new DataFrame contains responses with 40 characters or more using an assert statement.\n",
    "\n",
    "The airlines DataFrame is in your environment, and pandas is imported as pd.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Using the airlines DataFrame, store the length of each instance in the survey_response column in resp_length by using .str.len().\n",
    "* Isolate the rows of airlines with resp_length higher than 40.\n",
    "* Assert that the smallest survey_response length in airlines_survey is now bigger than 40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_response=['',\n",
    " 'It was terrible',\n",
    " 'I didnt like the flight',\n",
    " 'I hate this ',\n",
    " 'Not a fan',\n",
    " 'Bad',\n",
    " 'Horrible',\n",
    " 'Very poor',\n",
    " 'Unacceptable flight',\n",
    " 'It was awful',\n",
    " 'My fllight was really unpleasant',\n",
    " 'I am not a fan',\n",
    " 'I had a bad flight',\n",
    " 'It was very bad',\n",
    " 'it was horrible',\n",
    " 'Terrible',\n",
    " 'It was substandard',\n",
    " 'I did not enjoy the flight',\n",
    " 'The airport personnell forgot to alert us of delayed flights, the bathrooms could have been cleaner',\n",
    " 'The food in the airport was really really expensive - also no automatic escalators!',\n",
    " 'One of the other travelers was really loud and talkative and was making a scene and no one did anything about it',\n",
    " \"I don't remember answering the survey with these scores, my experience was great! \",\n",
    " 'The airport personnel kept ignoring my requests for directions ',\n",
    " 'The chair I sat in was extremely uncomfortable, I still have back pain to this day! ',\n",
    " 'I wish you were more like other airports, the flights were really disorganized! ',\n",
    " 'I was really unsatisfied with the wait times before the flight. It was unacceptable.',\n",
    " 'The flight was okay, but I did not really like the number of times I had to stop at security.',\n",
    " 'We were really slowed down by security measures, I missed my flight because of it! ',\n",
    " 'There was a spill on the aisle next to the bathroom and it took hours to clean!',\n",
    " 'I felt very unsatisfied by how long the flight took to take off.']\n",
    "\n",
    "airlines['survey_response'] = pd.DataFrame(survey_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18    The airport personnell forgot to alert us of d...\n",
      "19    The food in the airport was really really expe...\n",
      "20    One of the other travelers was really loud and...\n",
      "21    I don't remember answering the survey with the...\n",
      "22    The airport personnel kept ignoring my request...\n",
      "23    The chair I sat in was extremely uncomfortable...\n",
      "24    I wish you were more like other airports, the ...\n",
      "25    I was really unsatisfied with the wait times b...\n",
      "27    We were really slowed down by security measure...\n",
      "28    There was a spill on the aisle next to the bat...\n",
      "29    I felt very unsatisfied by how long the flight...\n",
      "Name: survey_response, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Store length of each row in survey_response column\n",
    "resp_length = airlines['survey_response'].str.len()\n",
    "\n",
    "# Find rows in airlines where resp_length > 40\n",
    "airlines_survey = airlines[resp_length > 40]\n",
    "\n",
    "# Assert minimum survey_response length is > 40\n",
    "assert airlines_survey['survey_response'].str.len().min() > 40\n",
    "\n",
    "# Print new survey_response column\n",
    "print(airlines_survey['survey_response'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('datacamp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d7dbeb1711c1dccb8cce60042c5bc5c0a3d59246e11fec6876b459dbf8bbb97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
