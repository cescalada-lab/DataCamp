{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t for proportions?\n",
    "Some of the hypothesis tests in this course have used a $z$ test statistic and some have used a $t$ test statistic. To get the correct p-value, you need to use the right type of test statistic.\n",
    "\n",
    "Do tests of proportion(s) use a $z$ or a $t$ test statistic and why?\n",
    "\n",
    "## ANSWER:\n",
    "\n",
    "* $z$: The test statistic for proportion(s) has only one estimate of a parameter instead of two.\n",
    "\n",
    "``The t-test is needed for tests of mean(s) since you are estimating two unknown quantities, which leads to more variability.``\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for single proportions\n",
    "In Chapter 1, you calculated a p-value for a test hypothesizing that the proportion of late shipments was greater than 6%. In that chapter, you used a bootstrap distribution to estimate the standard error of the statistic. An alternative is to use an equation for the standard error based on the sample proportion, hypothesized proportion, and sample size.\n",
    "\n",
    " $$ z = \\dfrac{\\hat{p} - p_{0}}{\\sqrt{\\dfrac{p_{0}*(1-p_{0})}{n}}} $$\n",
    " \n",
    "\n",
    "You'll revisit the p-value using this simpler calculation.\n",
    "\n",
    "late_shipments is available. pandas and numpy are available under their usual aliases, and norm is loaded from scipy.stats.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Hypothesize that the proportion of late shipments is 6%.\n",
    "* Calculate the sample proportion of shipments where late equals \"Yes\".\n",
    "* Calculate the number of observations in the sample.\n",
    "* Calculate the numerator and denominator of the z-score.\n",
    "* Calculate the z-score as the ratio of these numbers.\n",
    "* Transform the z-score into a p-value, remembering that this is a \"greater than\" alternative hypothesis.\n",
    "\n",
    "``While bootstrapping can be used to estimate the standard error of any statistic, it is computationally intensive. For proportions, using a simple equation of the hypothesized proportion and sample size is easier to compute.``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesize that the proportion of late shipments is 6%\n",
    "p_0 = 0.06\n",
    "\n",
    "# Calculate the sample proportion of late shipments\n",
    "p_hat = (late_shipments['late'] == \"Yes\").mean()\n",
    "\n",
    "# Calculate the sample size\n",
    "n = len(late_shipments)\n",
    "\n",
    "# Calculate the numerator and denominator of the test statistic\n",
    "numerator = p_hat - p_0\n",
    "denominator = np.sqrt(p_0 * (1 - p_0) / n)\n",
    "\n",
    "# Calculate the test statistic\n",
    "z_score = numerator / denominator\n",
    "\n",
    "# Calculate the p-value from the z-score\n",
    "p_value = 1 - norm.cdf(z_score)\n",
    "\n",
    "# Print the p-value\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for two proportions\n",
    "You may wonder if the amount paid for freight affects whether or not the shipment was late. Recall that in the late_shipments dataset, whether or not the shipment was late is stored in the late column. Freight costs are stored in the freight_cost_group column, and the categories are \"expensive\" and \"reasonable\".\n",
    "\n",
    "The hypotheses to test, with \"late\" corresponding to the proportion of late shipments for that group, are\n",
    "\n",
    "$H_0$: $late_{\\text{expensive}} -  late_{\\text{reasonable}} = 0$\n",
    "\n",
    "$H_A$: $late_{\\text{expensive}} -  late_{\\text{reasonable}} > 0$\n",
    "\n",
    "p_hats contains the estimates of population proportions (sample proportions) for the \"expensive\" and \"reasonable\" groups. ns contains the sample sizes for these groups. p_hats and ns have been printed for you.\n",
    "\n",
    "pandas and numpy have been imported under their usual aliases, and norm is available from scipy.stats.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Calculate the pooled sample proportion $\\hat{p}$, from p_hats and ns.\n",
    "\n",
    "$$\\hat{p} = \\frac{n_{\\text{expensive}} \\times \\hat{p}_{\\text{expensive}} + n_{\\text{reasonable}} \\times \\hat{p}_{\\text{reasonable}}}{n_{\\text{expensive}} + n_{\\text{reasonable}}}$$\n",
    "\n",
    "* Calculate the standard error of the sample using this equation.\n",
    "\n",
    "$$\\text{SE}(\\hat{p}_{\\text{expensive}} - \\hat{p}_{\\text{reasonable}}) = \\sqrt{\\dfrac{\\hat{p} \\times (1 - \\hat{p})}{n_{\\text{expensive}}} + \\dfrac{\\hat{p} \\times (1 - \\hat{p})}{n_{\\text{reasonable}}}}$$\n",
    "\n",
    "* Calculate the pooled sample proportion times one minus the pooled sample proportion.\n",
    "* Divide p_hat_times_not_p_hat by the sample sizes and sum those two values.\n",
    "* Calculate the square root of p_hat_times_not_p_hat_over_ns.\n",
    "\n",
    "* Calculate the z-score using the following equation.\n",
    "\n",
    "$$ z = \\frac{(\\hat{p}_{\\text{expensive}} - \\hat{p}_{\\text{reasonable}})}{\\text{SE}(\\hat{p}_{\\text{expensive}} - \\hat{p}_{\\text{reasonable}})}\n",
    "$$\n",
    "\n",
    "* Calculate the p-value from the z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the pooled estimate of the population proportion\n",
    "p_hat = (p_hats[\"reasonable\"] * ns[\"reasonable\"] + p_hats[\"expensive\"] * ns[\"expensive\"]) / (ns[\"reasonable\"] + ns[\"expensive\"])\n",
    "\n",
    "# Calculate p_hat one minus p_hat\n",
    "p_hat_times_not_p_hat = p_hat * (1 - p_hat)\n",
    "\n",
    "# Divide this by each of the sample sizes and then sum\n",
    "p_hat_times_not_p_hat_over_ns = p_hat_times_not_p_hat / ns[\"expensive\"] + p_hat_times_not_p_hat / ns[\"reasonable\"]\n",
    "\n",
    "# Calculate the standard error\n",
    "std_error = np.sqrt(p_hat_times_not_p_hat_over_ns)\n",
    "\n",
    "# Calculate the z-score\n",
    "z_score = (p_hats[\"expensive\"] - p_hats[\"reasonable\"]) / std_error\n",
    "\n",
    "# Calculate the p-value from the z-score\n",
    "p_value = 1 - norm.cdf(z_score)\n",
    "\n",
    "# Print p_value\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# proportions_ztest() for two samples\n",
    "That took a lot of effort to calculate the p-value, so while it is useful to see how the calculations work, it isn't practical to do in real-world analyses. For daily usage, it's better to use the statsmodels package.\n",
    "\n",
    "Recall the hypotheses.\n",
    "\n",
    "$H_0$: $late_{\\text{expensive}} -  late_{\\text{reasonable}} = 0$\n",
    "\n",
    "$H_A$: $late_{\\text{expensive}} -  late_{\\text{reasonable}} > 0$\n",
    "\n",
    "late_shipments is available, containing the freight_cost_group column. numpy and pandas have been loaded under their standard aliases, and proportions_ztest has been loaded from statsmodels.stats.proportion.\n",
    "\n",
    "## Intructions\n",
    "\n",
    "* Get the counts of the late column grouped by freight_cost_group.\n",
    "* Extract the number of \"Yes\"'s for the two groups into a numpy array, specifying the 'expensive' count and then 'reasonable'.\n",
    "* Determine the overall number of rows in each freight_cost_group as a numpy array, specifying 'expensive' and then 'reasonable'.\n",
    "* Run a z-test using proportions_ztest(), specifying alternative as \"larger\".\n",
    "\n",
    "``statsmodels's .proportions_ztest() method gives the same results with less effort.``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the late column values for each freight_cost_group\n",
    "late_by_freight_cost_group = late_shipments.groupby(\"freight_cost_group\")['late'].value_counts()\n",
    "\n",
    "# Put the two \"Yes\" counts into an array\n",
    "success_counts = np.array([45, 16])\n",
    "\n",
    "# Put the two group counts into an array\n",
    "n = np.array([45 + 500, 16 + 439])\n",
    "\n",
    "# Run a z-test on the two proportions\n",
    "stat, p_value = proportions_ztest(count=success_counts, nobs=n,\n",
    "                                  alternative=\"larger\")\n",
    "\n",
    "# Print the results\n",
    "print(stat, p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The chi-square distribution\n",
    "Chi-square hypothesis tests rely on the chi-square distribution. Like the t-distribution, it has degrees of freedom and non-centrality parameters.\n",
    "\n",
    "The plots show the PDF and CDF for a chi-square distribution (solid black line), and for comparison show a normal distribution with the same mean and variance (gray dotted line).\n",
    "\n",
    "Which statement about the the chi-square distribution is true?\n",
    "\n",
    "## ANSWER:\n",
    "* As you increase the degrees of freedom or the non-centrality, the chi-square distribution PDF and CDF curves get closer to those of a normal distribution.\n",
    "\n",
    "``Like the t-distribution, the chi-square distribution has degrees of freedom and non-centrality parameters. When these numbers are large, the chi-square distribution can be approximated by a normal distribution.``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many tails for chi-square tests?\n",
    "Unlike pingouin.ttest() and statsmodels.stats.proportion.proportions_ztest(), pingouin.chi2_independence() does not have an alternative argument to specify which tails are considered by the alternative hypothesis.\n",
    "\n",
    "Which tail is almost always considered in chi-square tests?\n",
    "\n",
    "## ANSWER:\n",
    "* Right-tailed\n",
    "\n",
    "````\n",
    "Left-tails tend to be more important when test statistics are negative, which isn't possible when it is a square number.\n",
    "\n",
    "Two-tails are important when differences between observations and expected values can occur in two directions, which tends to not be the case with chi-square tests.\n",
    "\n",
    "The chi-square test statistic is a square number, so it is always non-negative, so only the right tail tends to be of interest.\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi-square test of independence\n",
    "The chi-square independence test compares proportions of successes of one categorical variable across the categories of another categorical variable.\n",
    "\n",
    "Trade deals often use a form of business shorthand in order to specify the exact details of their contract. These are International Chamber of Commerce (ICC) international commercial terms, or incoterms for short.\n",
    "\n",
    "The late_shipments dataset includes a vendor_inco_term that describes the incoterms that applied to a given shipment. The choices are:\n",
    "\n",
    "* EXW: \"Ex works\". The buyer pays for transportation of the goods.\n",
    "* CIP: \"Carriage and insurance paid to\". The seller pays for freight and insurance until the goods board a ship.\n",
    "* DDP: \"Delivered duty paid\". The seller pays for transportation of the goods until they reach a destination port.\n",
    "* FCA: \"Free carrier\". The seller pays for transportation of the goods.\n",
    "\n",
    "Perhaps the incoterms affect whether or not the freight costs are expensive. Test these hypotheses with a significance level of 0.01.\n",
    "\n",
    "$H_0$: vendor_inco_term and freight_cost_group are independent.\n",
    "\n",
    "$H_A$: vendor_inco_term and freight_cost_group are associated.\n",
    "\n",
    "late_shipments is available, and the following have been loaded: matplotlib.pyplot as plt, pandas as pd, and pingouin.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Calculate the proportion of freight_cost_group in late_shipments grouped by vendor_inco_term.\n",
    "* Unstack the .value_counts() result to be in wide format instead of long.\n",
    "* Create a proportional stacked bar plot with bars filled based on freight_cost_group across the levels of vendor_inco_term.\n",
    "* Perform a chi-square test of independence on freight_cost_group and vendor_inco_term in the late_shipments dataset.\n",
    "* Question\n",
    "    * What should you conclude from the hypothesis test?\n",
    "    * ANSWER: \n",
    "    * Reject the null hypothesis and conclude that vendor_inco_term and freight_cost_group are associated.\n",
    "\n",
    "``Independence insight! The test to compare proportions of successes in a categorical variable across groups of another categorical variable is called a chi-square test of independence.``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of freight_cost_group grouped by vendor_inco_term\n",
    "props = late_shipments.groupby('vendor_inco_term')['freight_cost_group'].value_counts(normalize=True)\n",
    "\n",
    "# Convert props to wide format\n",
    "wide_props = props.unstack()\n",
    "\n",
    "# Proportional stacked bar plot of freight_cost_group vs. vendor_inco_term\n",
    "wide_props.plot(kind=\"bar\", stacked=True)\n",
    "plt.show()\n",
    "\n",
    "# Determine if freight_cost_group and vendor_inco_term are independent\n",
    "expected, observed, stats = pingouin.chi2_independence(data=late_shipments, x=\"vendor_inco_term\", y=\"freight_cost_group\")\n",
    "\n",
    "# Print results\n",
    "print(stats[stats['test'] == 'pearson']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing goodness of fit\n",
    "The chi-square goodness of fit test compares proportions of each level of a categorical variable to hypothesized values. Before running such a test, it can be helpful to visually compare the distribution in the sample to the hypothesized distribution.\n",
    "\n",
    "Recall the vendor incoterms in the late_shipments dataset. You hypothesize that the four values occur with these frequencies in the population of shipments.\n",
    "\n",
    "* EXW: 0.75\n",
    "* CIP: 0.05\n",
    "* DDP: 0.1\n",
    "* FCA: 0.1\n",
    "\n",
    "These frequencies are stored in the hypothesized DataFrame.\n",
    "\n",
    "The incoterm_counts DataFrame stores the .value_counts() of the vendor_inco_term column.\n",
    "\n",
    "late_shipments is available; pandas and matplotlib.pyplot are loaded with their standard aliases.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Find the number of rows in late_shipments.\n",
    "* Add a column named n to the hypothesized DataFrame storing the prop column times n_total.\n",
    "* Create a bar graph of 'n' versus 'vendor_inco_term' for the incoterm_counts data, specifying a yellow color and an alpha of 0.5.\n",
    "* Add blue points to the plot showing the results from hypothesized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of rows in late_shipments\n",
    "n_total = len(late_shipments)\n",
    "\n",
    "# Create n column that is prop column * n_total\n",
    "hypothesized[\"n\"] = hypothesized[\"prop\"] * n_total\n",
    "\n",
    "# Make a yellow bar graph of vendor_inco_term versus n\n",
    "plt.bar(incoterm_counts['vendor_inco_term'], incoterm_counts['n'], color=\"yellow\", alpha=0.5)\n",
    "\n",
    "# Add blue points for hypothesized counts\n",
    "plt.scatter(hypothesized['vendor_inco_term'], hypothesized['n'],color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi-square test of goodness of fit\n",
    "\n",
    "The bar plot of vendor_inco_term suggests that the distribution across the four categories was quite close to the hypothesized distribution. You'll need to perform a chi-square goodness of fit test to see whether the differences are statistically significant.\n",
    "\n",
    "Recall the hypotheses for this type of test:\n",
    "\n",
    "$H_0$: The sample matches with the hypothesized distribution.\n",
    "\n",
    "$H_A$: The sample does not match with the hypothesized distribution.\n",
    "\n",
    "To decide which hypothesis to choose, we'll set a significance level of 0.1.\n",
    "\n",
    "late_shipments, incoterm_counts, and hypothesized from the last exercise are available. chisquare from scipy.stats has been loaded.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Using the incoterm_counts and hypothesized datasets, perform a chi-square goodness of fit test on vendor_inco_term.\n",
    "* Question\n",
    "    * What should you conclude from the hypothesis test?\n",
    "    * ANSWER: Reject the null hypothesis and conclude that vendor_inco_term does not follow the distribution specified by hypothesized_props.\n",
    "\n",
    "``The test to compare the proportions of a categorical variable to a hypothesized distribution is called a chi-square goodness of fit test.``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a goodness of fit test on vendor_inco_term\n",
    "gof_test = chisquare(f_obs=incoterm_counts['n'], f_exp=hypothesized['n'])\n",
    "\n",
    "\n",
    "# Print gof_test results\n",
    "print(gof_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
